{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT-Based Audio Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import binascii\n",
    "from scipy.io.wavfile import read, write\n",
    "from IPython.display import Audio\n",
    "from numpy.fft import fft, ifft, fftfreq, fftshift, ifftshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in an audio file, taking note of its sampling rate and number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'speech.wav'  # replace with your chosen audio file\n",
    "sr, original = read(f'audio/{filename}')\n",
    "N = len(original)\n",
    "\n",
    "print(f\"Sampling Rate is {sr} Hz\")\n",
    "print(f\"Total number of samples is {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can listen to the original audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(original, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the spectrogram, we get a visual representation of the audio signal temporally and across the frequency spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.specgram(original, Fs=sr)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Spectrogram of Original Audio')\n",
    "plt.savefig('output/original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the FFT of the audio signal, and align the zero frequency component to the center of the frequency spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ft = fftshift(fft(original, N))\n",
    "original_ft_freq = fftfreq(N)\n",
    "plt.plot(original_ft_freq, abs(original_ft))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to embed a text watermark into our audio file, we first convert the watermark into binary. This allows us to embed each individual bit into our audio signal. Embedding at this level ensures that our algorithm poses minimal risk to the sound of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark = \"EECS351\" # replace with your chosen watermark\n",
    "watermark_bits = ''.join(format(ord(i), '08b') for i in watermark)\n",
    "\n",
    "print(f\"Watermark: {watermark}\")\n",
    "print(f\"Binary array to embed: {watermark_bits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then prepare to embed using frame-wise encoding. This is the process of segmenting an audio signal into small frames, with each one representing a portion of the signal over time. Each frame is processed individually, with a small bit of the watermark embedded into its associated frame. Here, we set the number of samples per frame, and also set the frequency band that we want to embed the watermark at.\n",
    "\n",
    "Using these details, we convert our signal into a matrix representation where each row is a frame and the columns represent the samples in that frame. This allows us to easily embed each bit of the watermark into its associated frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = len(watermark_bits) # total number of bits to embed\n",
    "samples_per_bit = 10 # number of samples used to embed each bit\n",
    "total_samples = frame * samples_per_bit # total number of samples to embed\n",
    "center = (N/2) + 1\n",
    "\n",
    "embed_freq = 5000 # frequency where watermark is embedded\n",
    "\n",
    "a = 0.1 # scaling factor\n",
    "\n",
    "X_mag = np.abs(original_ft)\n",
    "X_phase = np.angle(original_ft)\n",
    "\n",
    "Y = X_mag\n",
    "X_embed = X_mag[int(center - embed_freq - total_samples):int(center - embed_freq)]\n",
    "X_mat = X_embed.reshape(frame, samples_per_bit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dividing the selected frequency band is divided into short frames, we begin embedding a single secret bit into each frame. All samples in each frame are changed based on the corresponding secret bit. \n",
    "\n",
    "If the secret bit is 0, all samples in the frame should be set to the average value of all FFT magnitudes in the frame. This creates a flat, uniform signature for a 0 bit. If the secret bit is 1, we divide the FFT samples in the frame into two groups. The samples in the first group are set to a scaled down average value and the samples of the second group are set to a scaled up average value. This creates an asymmetric signature for a 1 bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(frame):\n",
    "    avg = 0\n",
    "    \n",
    "    # take average of the samples in given frame\n",
    "    for j in range(samples_per_bit):  \n",
    "        avg = avg + X_mat[i][j]\n",
    "    avg = avg / samples_per_bit\n",
    "\n",
    "    if watermark_bits[i] == '0':  # if the bit to encode is '0'\n",
    "        print('0', end=' ')\n",
    "        for j in range(samples_per_bit):\n",
    "            X_mat[i][j] = avg  # set all 10 samples to same average value\n",
    "\n",
    "    else:  # if the bit to encode is '1'\n",
    "        print('1', end=' ')\n",
    "        for j in range(int(samples_per_bit / 2)):  # access the first half of the frame\n",
    "            X_mat[i][j] = a * avg  # set FFT samples to scaled down average value\n",
    "        for j in range(int(samples_per_bit / 2), samples_per_bit):  # access the second half of the frame\n",
    "            X_mat[i][j] = (2 - a) * avg  # set FFT samples to scaled up average value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After embedding the watermark into the matrix representation of our signal, we need to convert back to a vector in order to reconstruct the audio signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec = X_mat.reshape(total_samples)  # bring it back to vector/array\n",
    "\n",
    "# define range for adding embeddings back to final fft vec with embeddings\n",
    "range_embed_1 = range(int(center - embed_freq - total_samples), int(center - embed_freq))\n",
    "range_embed_2 = range(int(center + embed_freq + 1),\n",
    "                      int(center + embed_freq + total_samples + 1))\n",
    "\n",
    "Y[range_embed_1] = X_vec\n",
    "Y[range_embed_2] = X_vec[::-1]  # reversed for symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.multiply(Y, np.exp(1j * X_phase))\n",
    "plt.plot(original_ft_freq, abs(Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked = ifft(ifftshift(Y1))\n",
    "write('output/watermarked.wav', int(sr), watermarked.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can listen to the watermarked audio file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(watermarked.real, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode Watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to begin recovering the embedded watermark, we need to read in the watermarked audio file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, watermarked = read('output/watermarked.wav')\n",
    "N = len(watermarked)\n",
    "\n",
    "print(f\"Sampling Rate is {sr} Hz\")\n",
    "print(f\"Total number of samples is {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot the spectrogram of the watermarked audio file. This is useful because it provides a visual representation of any artifacts or differences between the original audio and the watermarked audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.specgram(watermarked, Fs=sr)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title(f'Spectrogram of Watermarked Audio at {embed_freq} Hz')\n",
    "plt.savefig('output/watermarked.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the FFT of the watermarked signal, and convert the signal into a matrix just like the representation we used during embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = fftshift(fft(watermarked))\n",
    "Y2_abs = abs(Y2)\n",
    "# find in correct frequency window\n",
    "detect_window = Y2_abs[int(center - embed_freq - total_samples):int(center - embed_freq)]\n",
    "detect_window_mat = detect_window.reshape(frame, samples_per_bit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implementation of watermarking uses informed detection, which makes decoding easier by supplementing the algorithm with some information about how the watermark was embedded. The information provided includes:\n",
    "- Total number of bits embedded\n",
    "\n",
    "- Total number of samples embedded\n",
    "\n",
    "- Number of samples used to embed each bit\n",
    "\n",
    "- Embedding frequency\n",
    "\n",
    "- Scaling factor\n",
    "\n",
    "Using this information, we can check each frame for the unique signatures that we encoded during embedding. Based on the values of the samples we find in each frame, we make a bit decision (0 or 1) and append that value to our recovered binary watermark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_binary = ''  # binary string\n",
    "\n",
    "for i in range(frame):\n",
    "    avg = 0\n",
    "    one_count = 0\n",
    "    zero_count = 0\n",
    "\n",
    "    for j in range(samples_per_bit):  # find average\n",
    "        avg = avg + detect_window_mat[i][j]\n",
    "    avg = avg / samples_per_bit \n",
    "\n",
    "    # checking the first half of the frame\n",
    "    for j in range(int(samples_per_bit / 2)):\n",
    "        if (detect_window_mat[i][j] >= (1 + a) * avg / 2):  # decision for '0'\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            one_count += 1\n",
    "\n",
    "    # checking the second half of the frame\n",
    "    for j in range(int(samples_per_bit / 2), samples_per_bit - 1):\n",
    "        if (detect_window_mat[i][j] < (3 - a) * avg / 2):\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            one_count += 1\n",
    "\n",
    "    # final bit decision\n",
    "    if (one_count > zero_count):\n",
    "        recovered_binary = recovered_binary + '1'\n",
    "    else:\n",
    "        recovered_binary = recovered_binary + '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the decoding algorithm, we recover a binary number that we can convert to a string using the \"unhexlify\" function. If everything worked correctly, we should recover the watermark we chose during embedding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_watermark = binascii.unhexlify(\n",
    "    '%x' % int(recovered_binary, 2)).decode('utf-8')\n",
    "\n",
    "print(f\"Recovered binary array is {recovered_binary}\")\n",
    "print(f\"Recovered watermark is {recovered_watermark}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "351_watermark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
